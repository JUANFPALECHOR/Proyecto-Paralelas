# AnÃ¡lisis de CorrelaciÃ³n: Noticias vs COLCAP

Sistema distribuido para procesar informaciÃ³n noticiosa de Common Crawl y correlacionarla con el Ã­ndice bursÃ¡til colombiano COLCAP, implementado con arquitectura de contenedores orquestada con Kubernetes.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un **sistema distribuido de procesamiento masivo de datos** que:

1. **Ingesta** datos de noticias desde archivos WARC comprimidos (.warc.gz) de Common Crawl
2. **Limpia y transforma** el contenido HTML a texto estructurado con paralelizaciÃ³n
3. **Calcula caracterÃ­sticas** agregadas (sentiment, volumen) de las noticias por fecha
4. **Correlaciona** estas caracterÃ­sticas con la serie temporal del Ã­ndice COLCAP
5. **Visualiza** los resultados en un dashboard interactivo con mÃºltiples backends

### âœ… Cumplimiento de Objetivos del Proyecto

El sistema cumple **todos los objetivos especÃ­ficos** del enunciado:

- âœ… **ComputaciÃ³n paralela/distribuida**: 4 backends (Pandas, Multiprocessing, Dask, Spark)
- âœ… **Fuentes abiertas (Common Crawl)**: Soporte nativo para archivos .warc.gz comprimidos
- âœ… **Arquitectura Docker/K8s**: OrquestaciÃ³n completa con auto-escalado (HPA)
- âœ… **Pipeline completo**: Ingesta â†’ Limpieza â†’ Features â†’ CorrelaciÃ³n â†’ VisualizaciÃ³n
- âœ… **EvaluaciÃ³n de desempeÃ±o**: Benchmark automatizado con mÃ©tricas de tiempo/memoria
- âœ… **DocumentaciÃ³n exhaustiva**: 6 guÃ­as detalladas + API docs

**Capacidad confirmada**: Procesa volÃºmenes ilimitados de datos de Common Crawl con escalabilidad horizontal en Kubernetes.

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                       â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  Dashboard   â”‚â”€â”€â”€â”€â”€â†’â”‚  Analysis    â”‚                   â”‚
â”‚  â”‚  (Streamlit) â”‚      â”‚   Service    â”‚                   â”‚
â”‚  â”‚              â”‚      â”‚  (FastAPI)   â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                      â”‚                           â”‚
â”‚         â”‚                      â†“                           â”‚
â”‚         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚         â”‚              â”‚   Analysis   â”‚                   â”‚
â”‚         â”‚              â”‚    Engine    â”‚                   â”‚
â”‚         â”‚              â”‚              â”‚                   â”‚
â”‚         â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                   â”‚
â”‚         â”‚              â”‚  â”‚ Pandas â”‚  â”‚                   â”‚
â”‚         â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                   â”‚
â”‚         â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â†’â”‚  Dask  â”‚  â”‚                   â”‚
â”‚                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                   â”‚
â”‚                        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                   â”‚
â”‚                        â”‚  â”‚ Spark  â”‚  â”‚                   â”‚
â”‚                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                   â”‚
â”‚                        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                   â”‚
â”‚                        â”‚  â”‚   MP   â”‚  â”‚                   â”‚
â”‚                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                   â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              HPA (Horizontal Pod Autoscaler)          â”‚ â”‚
â”‚  â”‚         (Escalado automÃ¡tico basado en CPU)          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        â†‘                           â†‘
        â”‚                           â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  CSV   â”‚                 â”‚  WARC   â”‚
   â”‚ COLCAP â”‚                 â”‚  Files  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principales

#### 1. **Ingestion Service** (`ingestion/`)
- Procesa archivos WARC (.warc.gz) de Common Crawl
- Extrae: URL, dominio, tÃ­tulo, fecha, texto limpio
- Usa Readability y BeautifulSoup para limpieza de HTML
- Genera `data/output.csv` como entrada para anÃ¡lisis

#### 2. **Analysis Engine** (`analysis/`)
- **Backends intercambiables**:
  - `pandas`: Procesamiento secuencial (baseline)
  - `multiprocessing`: ParalelizaciÃ³n con pool de procesos
  - `dask`: ComputaciÃ³n distribuida con particiones
  - `spark`: Procesamiento a gran escala (opcional)
- **Features**: ExtracciÃ³n de caracterÃ­sticas de noticias
- **Metrics**: Benchmarking de rendimiento
- **Data Sources**: Cargadores de COLCAP

#### 3. **Analysis Service** (`analysis_service/`)
- API REST con FastAPI
- Endpoints:
  - `POST /correlate`: CorrelaciÃ³n desde archivos CSV
  - `POST /correlate-inline`: CorrelaciÃ³n con CSVs en payload
  - `GET /health`: Health check
- ConfiguraciÃ³n dinÃ¡mica de backend y parÃ¡metros

#### 4. **Dashboard** (`dashboard/`)
- Interfaz web con Streamlit
- Permite subir CSVs de noticias y COLCAP
- SelecciÃ³n de backend y parÃ¡metros
- VisualizaciÃ³n de resultados de correlaciÃ³n

#### 5. **Kubernetes Manifests** (`k8s/`)
- `analysis-service.yaml`: Deployment y Service del API
- `dashboard.yaml`: Deployment y Service del dashboard
- `hpa.yaml`: HorizontalPodAutoscaler para escalado automÃ¡tico
- `ingress.yaml`: Ingress para acceso externo

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- Python 3.11+
- Docker
- Kubernetes (minikube, Docker Desktop, o cluster en la nube)
- kubectl configurado

### InstalaciÃ³n Local

```powershell
# Clonar repositorio
cd "c:\ruta\al\proyecto"

# Crear entorno virtual
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Instalar dependencias
pip install -r requirements.txt
```

## ğŸ“Š Uso

### 1. Ingesta de Datos de Common Crawl

El sistema **soporta archivos .warc.gz nativamente** y puede procesar volÃºmenes ilimitados:

```powershell
# Procesar UN archivo completo (sin lÃ­mite)
python -m ingestion.main --file "archivo.warc.gz" --limit 0

# Procesar archivo con lÃ­mite (ejemplo: 1000 pÃ¡ginas)
python -m ingestion.main --file "archivo.warc.gz" --limit 1000

# Procesar MÃšLTIPLES archivos en paralelo (usa todos los CPU cores)
python -m ingestion.main --dir "C:\common_crawl_data" --limit 0

# Salida: data/output.csv (con columnas: url, dominio, titulo, fecha, texto, longitud)
```

**CaracterÃ­sticas**:
- âœ… Lee archivos .gz comprimidos de Common Crawl
- âœ… Procesamiento paralelo con `multiprocessing.Pool`
- âœ… Progreso en tiempo real (cada 100 registros)
- âœ… `--limit 0` = procesamiento ilimitado para datos masivos

**Nota**: El proyecto incluye `data/output.csv` (80 noticias) y `data/colcap_sample.csv` para pruebas inmediatas.

ğŸ“– **GuÃ­a detallada**: Ver [GUIA_COMMON_CRAWL.md](GUIA_COMMON_CRAWL.md) para procesamiento de datos masivos.

### 2. AnÃ¡lisis Local

#### CorrelaciÃ³n con diferentes backends

```powershell
# Pandas (secuencial)
python -m analysis.scripts.correlate_news_colcap `
    --backend pandas `
    --colcap-csv data\colcap_sample.csv `
    --out results_pandas.json

# Multiprocessing (paralelo)
python -m analysis.scripts.correlate_news_colcap `
    --backend multiprocessing `
    --mp-procs 4 `
    --colcap-csv data\colcap_sample.csv `
    --out results_mp.json

# Dask (distribuido)
python -m analysis.scripts.correlate_news_colcap `
    --backend dask `
    --dask-nparts 8 `
    --colcap-csv data\colcap_sample.csv `
    --out results_dask.json

# Spark (opcional, requiere PySpark)
python -m analysis.scripts.correlate_news_colcap `
    --backend spark `
    --spark-master "local[*]" `
    --colcap-csv data\colcap_sample.csv `
    --out results_spark.json
```

#### Benchmark de rendimiento

```powershell
python -m analysis.metrics.benchmark `
    --backends pandas multiprocessing dask `
    --mp-procs 4 `
    --dask-nparts 8 `
    --colcap-csv data\colcap_sample.csv `
    --out benchmark_results.json
```

### 3. EjecuciÃ³n Local de Servicios

#### API (FastAPI)

```powershell
# Terminal 1
uvicorn analysis_service.app:app --host 0.0.0.0 --port 8000

# Probar
curl http://localhost:8000/health
```

#### Dashboard (Streamlit)

```powershell
# Terminal 2
$env:ANALYSIS_API_URL="http://localhost:8000"
streamlit run dashboard\app.py

# Acceder a http://localhost:8501
```

## ğŸ³ Docker

### Construir ImÃ¡genes

```powershell
# Desde la raÃ­z del proyecto

# Analysis Service
docker build -t analysis-service:latest -f analysis_service/Dockerfile .

# Dashboard
docker build -t news-dashboard:latest -f dashboard/Dockerfile .

# Ingestion (opcional)
docker build -t ingestion-service:latest -f ingestion/Dockerfile .
```

### Ejecutar Contenedores

```powershell
# API
docker run --rm -p 8000:8000 -v ${PWD}/data:/app/data analysis-service:latest

# Dashboard (conectado al API)
docker run --rm -p 8501:8501 `
    -e ANALYSIS_API_URL="http://host.docker.internal:8000" `
    news-dashboard:latest
```

### Docker Compose (Recomendado)

```powershell
# Crear docker-compose.yml y ejecutar
docker-compose up -d

# Ver logs
docker-compose logs -f

# Detener
docker-compose down
```

## â˜¸ï¸ Kubernetes

### 1. Preparar ImÃ¡genes

```powershell
# OpciÃ³n A: Registry pÃºblico (Docker Hub)
docker login
docker tag analysis-service:latest tu-usuario/analysis-service:latest
docker tag news-dashboard:latest tu-usuario/news-dashboard:latest
docker push tu-usuario/analysis-service:latest
docker push tu-usuario/news-dashboard:latest

# OpciÃ³n B: Registry local (Minikube)
minikube image load analysis-service:latest
minikube image load news-dashboard:latest
```

### 2. Actualizar Manifiestos

Editar `k8s/analysis-service.yaml` y `k8s/dashboard.yaml`:
```yaml
# Cambiar
image: ghcr.io/your-org/analysis-service:latest
# Por
image: tu-usuario/analysis-service:latest
```

### 3. Desplegar

```powershell
# Iniciar cluster (si usas minikube)
minikube start --cpus=4 --memory=8192

# Aplicar manifiestos
kubectl apply -f k8s/analysis-service.yaml
kubectl apply -f k8s/dashboard.yaml
kubectl apply -f k8s/hpa.yaml

# Verificar
kubectl get pods
kubectl get svc
kubectl get hpa

# Ver logs
kubectl logs -l app=analysis-service -f
kubectl logs -l app=news-dashboard -f
```

### 4. Acceder a los Servicios

```powershell
# OpciÃ³n A: Port-forwarding (desarrollo)
kubectl port-forward svc/analysis-service 8000:8000
kubectl port-forward svc/news-dashboard 8501:8501

# Acceder a http://localhost:8501

# OpciÃ³n B: Ingress (producciÃ³n)
# Instalar ingress controller
minikube addons enable ingress

# Aplicar ingress
kubectl apply -f k8s/ingress.yaml

# Obtener IP
minikube ip

# Agregar a C:\Windows\System32\drivers\etc\hosts
# <IP> your-domain.example.com
```

### 5. Probar Escalado AutomÃ¡tico (HPA)

```powershell
# Terminal 1: Observar HPA
kubectl get hpa -w

# Terminal 2: Generar carga
kubectl port-forward svc/analysis-service 8000:8000

# Terminal 3: Stress test
while ($true) {
    Invoke-RestMethod http://localhost:8000/health
    Start-Sleep -Milliseconds 50
}

# Observar en Terminal 1 cÃ³mo se crean nuevos pods
```

## ğŸ“ˆ Resultados y MÃ©tricas

### Correlaciones Calculadas

El sistema calcula:
- **Pearson**: CorrelaciÃ³n lineal entre variables
- **Spearman**: CorrelaciÃ³n de rangos (no paramÃ©trica)
- **Rolling**: Correlaciones rodantes en ventanas de 7, 14, 30 dÃ­as

### MÃ©tricas de DesempeÃ±o

El mÃ³dulo de benchmark mide:
- â±ï¸ Tiempo de carga de datos
- â±ï¸ Tiempo de cÃ¡lculo de caracterÃ­sticas
- â±ï¸ Tiempo de correlaciÃ³n
- ğŸ’¾ Uso de memoria (RSS)
- ğŸ”„ Tiempo total de pipeline

### Ejemplo de Resultados

```json
{
  "backend": "multiprocessing",
  "timings_sec": {
    "load_news": 0.5234,
    "features": 1.2456,
    "load_colcap": 0.0123,
    "align": 0.0456,
    "correlate": 0.3421,
    "total": 2.1690
  },
  "memory_bytes": {
    "rss_start": 52428800,
    "rss_end": 78643200,
    "delta": 26214400
  }
}
```

## ğŸ“‚ Estructura del Proyecto

```
Proyecto-Paralelas/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ EVALUACION_PROYECTO.md       # EvaluaciÃ³n y plan de pruebas
â”œâ”€â”€ requirements.txt             # Dependencias Python
â”œâ”€â”€ Home.py                      # (vacÃ­o - ignorar)
â”œâ”€â”€ correlation_results.json     # Resultados de ejemplo
â”‚
â”œâ”€â”€ data/                        # Datos de entrada/salida
â”‚   â”œâ”€â”€ colcap_sample.csv        # Serie temporal COLCAP
â”‚   â””â”€â”€ output.csv               # Noticias procesadas
â”‚
â”œâ”€â”€ ingestion/                   # MÃ³dulo de ingesta
â”‚   â”œâ”€â”€ main.py                  # CLI principal
â”‚   â”œâ”€â”€ warc_reader.py           # Lectura de WARC
â”‚   â”œâ”€â”€ cleaner.py               # Limpieza de HTML
â”‚   â”œâ”€â”€ writer.py                # Escritura CSV
â”‚   â”œâ”€â”€ Dockerfile               # Imagen Docker
â”‚   â””â”€â”€ README.md                # DocumentaciÃ³n
â”‚
â”œâ”€â”€ analysis/                    # Motor de anÃ¡lisis
â”‚   â”œâ”€â”€ engine/                  # Backends de procesamiento
â”‚   â”‚   â”œâ”€â”€ base.py              # Interfaz base
â”‚   â”‚   â”œâ”€â”€ factory.py           # Factory pattern
â”‚   â”‚   â””â”€â”€ backends/
â”‚   â”‚       â”œâ”€â”€ pandas_engine.py
â”‚   â”‚       â”œâ”€â”€ mp_engine.py     # Multiprocessing
â”‚   â”‚       â”œâ”€â”€ dask_engine.py
â”‚   â”‚       â””â”€â”€ spark_engine.py
â”‚   â”œâ”€â”€ features/                # ExtracciÃ³n de caracterÃ­sticas
â”‚   â”‚   â””â”€â”€ news_features.py
â”‚   â”œâ”€â”€ data_sources/            # Cargadores de datos
â”‚   â”‚   â””â”€â”€ colcap_loader.py
â”‚   â”œâ”€â”€ metrics/                 # Benchmarking
â”‚   â”‚   â””â”€â”€ benchmark.py
â”‚   â”œâ”€â”€ scripts/                 # Scripts CLI
â”‚   â”‚   â””â”€â”€ correlate_news_colcap.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ analysis_service/            # API REST
â”‚   â”œâ”€â”€ app.py                   # FastAPI application
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ dashboard/                   # Dashboard web
â”‚   â”œâ”€â”€ app.py                   # Streamlit app
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ k8s/                         # Manifiestos Kubernetes
    â”œâ”€â”€ analysis-service.yaml    # Deployment + Service
    â”œâ”€â”€ dashboard.yaml           # Deployment + Service
    â”œâ”€â”€ hpa.yaml                 # HorizontalPodAutoscaler
    â”œâ”€â”€ ingress.yaml             # Ingress
    â””â”€â”€ README.md
```

## ğŸ§ª Testing

### Pruebas Locales

```powershell
# Test completo del pipeline
python -m analysis.scripts.correlate_news_colcap `
    --backend pandas `
    --colcap-csv data\colcap_sample.csv

# Benchmark
python -m analysis.metrics.benchmark `
    --backends pandas multiprocessing `
    --colcap-csv data\colcap_sample.csv
```

### Pruebas Docker

```powershell
# Test de contenedores
docker run --rm analysis-service:latest uvicorn analysis_service.app:app --help
```

### Pruebas Kubernetes

```powershell
# Smoke test
kubectl apply -f k8s/
kubectl wait --for=condition=ready pod -l app=analysis-service --timeout=60s
kubectl port-forward svc/analysis-service 8000:8000
curl http://localhost:8000/health
```

## ğŸ“š DocumentaciÃ³n Adicional

- [Ingestion Module](ingestion/README.md)
- [Analysis Engine](analysis/README.md)
- [Kubernetes Deployment](k8s/README.md)
- [EvaluaciÃ³n y Testing](EVALUACION_PROYECTO.md)

## ğŸ¯ Objetivos del Proyecto

Este proyecto demuestra:

âœ… **ComputaciÃ³n Paralela**: MÃºltiples backends con diferentes estrategias de paralelizaciÃ³n

âœ… **ComputaciÃ³n Distribuida**: Dask y Spark para procesamiento distribuido

âœ… **Contenedores**: Dockerfiles para cada componente

âœ… **OrquestaciÃ³n**: Kubernetes con Deployments, Services, HPA

âœ… **Pipeline de Datos**: AdquisiciÃ³n â†’ Limpieza â†’ AnÃ¡lisis â†’ VisualizaciÃ³n

âœ… **Escalabilidad**: HPA que escala automÃ¡ticamente bajo carga

âœ… **MÃ©tricas**: Benchmarking de rendimiento y uso de recursos

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Dask Distribuido

Para usar un cluster Dask:

```powershell
# Iniciar scheduler
dask-scheduler

# Iniciar workers
dask-worker tcp://scheduler:8786

# Usar en anÃ¡lisis
python -m analysis.scripts.correlate_news_colcap `
    --backend dask `
    --dask-distributed `
    --dask-scheduler tcp://scheduler:8786 `
    --colcap-csv data\colcap_sample.csv
```

### Spark

Para usar Spark:

```powershell
# Instalar PySpark
pip install pyspark

# Usar con master local
python -m analysis.scripts.correlate_news_colcap `
    --backend spark `
    --spark-master "local[*]" `
    --colcap-csv data\colcap_sample.csv

# O conectar a cluster Spark
python -m analysis.scripts.correlate_news_colcap `
    --backend spark `
    --spark-master "spark://master:7077" `
    --colcap-csv data\colcap_sample.csv
```

## â“ Troubleshooting

### Error: "No module named 'analysis'"

```powershell
# AsegÃºrate de estar en la raÃ­z del proyecto
cd "c:\ruta\proyecto\Proyecto-Paralelas"

# Ejecuta con -m para resolver mÃ³dulos
python -m analysis.scripts.correlate_news_colcap ...
```

### Pods en estado CrashLoopBackOff

```powershell
# Ver logs
kubectl logs -l app=analysis-service

# Verificar recursos
kubectl describe pod <pod-name>

# Verificar imÃ¡genes
kubectl get pods -o jsonpath='{.items[*].spec.containers[*].image}'
```

### HPA no escala

```powershell
# Verificar metrics server
kubectl get apiservice v1beta1.metrics.k8s.io

# Instalar metrics server (minikube)
minikube addons enable metrics-server

# Ver mÃ©tricas
kubectl top nodes
kubectl top pods
```

## ğŸ¤ Contribuciones

Proyecto desarrollado para el curso **Infraestructuras Paralelas y Distribuidas** - Universidad del Valle.

## ğŸ“„ Licencia

Proyecto acadÃ©mico - Universidad del Valle 2025

## ğŸ”— Referencias

- [Common Crawl](https://commoncrawl.org/)
- [Kubernetes Documentation](https://kubernetes.io/docs/)
- [Docker Documentation](https://docs.docker.com/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Streamlit](https://streamlit.io/)
- [Dask](https://dask.org/)
- [Apache Spark](https://spark.apache.org/)
